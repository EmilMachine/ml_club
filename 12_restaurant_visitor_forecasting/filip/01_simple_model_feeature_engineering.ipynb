{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01_simple_model_feeature_engineering\n",
    "\n",
    "* split air_visit_data in a train and test.\n",
    "* build a few features\n",
    "    * previous visits\n",
    "    * holiday/weekday features\n",
    "* train different model types\n",
    "* evaluate expected error (RMSLE)\n",
    "* submit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#https://www.kaggle.com/irinaabdullaeva/welcome-recruit-restaurant-visitor-forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'air_reserve': pd.read_csv('data/air_reserve.csv'),\n",
    "    'air_store_info': pd.read_csv('data/air_store_info.csv'),\n",
    "    'air_visit_data': pd.read_csv('data/air_visit_data.csv'),\n",
    "    'date_info': pd.read_csv('data/date_info.csv'),\n",
    "    'hpg_reserve': pd.read_csv('data/hpg_reserve.csv'),\n",
    "    'hpg_store_info': pd.read_csv('data/hpg_store_info.csv'),\n",
    "    'sample_submission': pd.read_csv('data/sample_submission.csv'),\n",
    "    'store_id_relation': pd.read_csv('data/store_id_relation.csv'),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Training and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The submission dateset contains data between 2017-04-23 and 2017-05-31\n",
      "The submission dateset contains 821 unique air stores\n"
     ]
    }
   ],
   "source": [
    "sumbission_df = data['sample_submission'].copy()\n",
    "sumbission_df['store_id'] = sumbission_df.apply(lambda x: '_'.join(x['id'].split('_')[:-1]),axis=1)\n",
    "sumbission_df['visit_date'] = sumbission_df.apply(lambda x: x['id'].split('_')[-1],axis=1)\n",
    "print('The submission dateset contains data between {min_date} and {max_date}'.format(min_date=min(sumbission_df['visit_date']), max_date=max(sumbission_df['visit_date'])))\n",
    "print('The submission dateset contains {unique_air_stores} unique air stores'.format(unique_air_stores=len(sumbission_df['store_id'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The air_visit_data dateset contains data between 2016-01-01 and 2017-04-22\n",
      "The air_visit_data dateset contains 829 unique air stores\n"
     ]
    }
   ],
   "source": [
    "air_visit_df = data['air_visit_data'].copy()\n",
    "print('The air_visit_data dateset contains data between {min_date} and {max_date}'.format(min_date=min(air_visit_df['visit_date']), max_date=max(air_visit_df['visit_date'])))\n",
    "print('The air_visit_data dateset contains {unique_air_stores} unique air stores'.format(unique_air_stores=len(air_visit_df['air_store_id'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_visit_df = air_visit_df.rename(columns={'air_store_id':'store_id'})\n",
    "train_test_split_date = '2017-01-01'\n",
    "train_df = air_visit_df[air_visit_df['visit_date'] < train_test_split_date]\n",
    "test_df = air_visit_df[air_visit_df['visit_date'] >= train_test_split_date]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "def calc_instance_features(df):\n",
    "    df['visit_datetime'] = pd.to_datetime(df['visit_date'])\n",
    "    df['year'] = df['visit_datetime'].dt.year\n",
    "    df['month'] = df['visit_datetime'].dt.month\n",
    "    df['day'] = df['visit_datetime'].dt.day\n",
    "    df['weekday'] = df['visit_datetime'].dt.weekday\n",
    "    return df\n",
    "    \n",
    "train_df = calc_instance_features(train_df)\n",
    "test_df = calc_instance_features(test_df)\n",
    "\n",
    "store_mean_2016 = train_df[['store_id','visitors']].groupby('store_id',as_index=False).mean().rename(columns={'visitors':'store_visitors_mean'})\n",
    "store_weekday_mean_2016 = train_df[['store_id','visitors','weekday']].groupby(['store_id','weekday'], as_index=False).mean().rename(columns={'visitors':'store_visitors_weekday_mean'})\n",
    "\n",
    "train_df = pd.merge(train_df, store_mean_2016, on=['store_id'],how='left').fillna(0)\n",
    "train_df = pd.merge(train_df, store_weekday_mean_2016, on=['store_id','weekday'],how='left').fillna(0)\n",
    "\n",
    "test_df = pd.merge(test_df, store_mean_2016, on=['store_id'],how='left').fillna(0)\n",
    "test_df = pd.merge(test_df, store_weekday_mean_2016, on=['store_id','weekday'],how='left').fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = 'visitors'\n",
    "features_cols = ['month','day','weekday','store_visitors_mean','store_visitors_weekday_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "train_sample_df = train_df.sample(n = 10000)\n",
    "clf = LogisticRegression(random_state=0).fit(X=train_sample_df[features_cols], y=train_sample_df[target_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4466748875752145"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "test_df['predicted'] = clf.predict(test_df[features_cols])\n",
    "rsmle = metrics.mean_squared_log_error(y_true=test_df['visitors'], y_pred=test_df['predicted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumbission_df = calc_instance_features(sumbission_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumbission_df = pd.merge(sumbission_df, store_mean_2016, on=['store_id'],how='left').fillna(0)\n",
    "sumbission_df = pd.merge(sumbission_df, store_weekday_mean_2016, on=['store_id','weekday'],how='left').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumbission_df['visitors'] = clf.predict(sumbission_df[features_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumbission_df[['id','visitors']].to_csv('01_simple_sumission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1.06M/1.06M [00:05<00:00, 221kB/s]\n",
      "Successfully submitted to Recruit Restaurant Visitor Forecasting"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c recruit-restaurant-visitor-forecasting -f 01_simple_sumission.csv -m 01_simple_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
