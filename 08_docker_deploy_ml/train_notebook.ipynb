{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# packages used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# misc\n",
    "from IPython.display import display, HTML\n",
    "import numpy as np\n",
    "\n",
    "# DATA - prep\n",
    "#kaggle\n",
    "import pandas as pd\n",
    "import sklearn.model_selection\n",
    "\n",
    "# ML - models \n",
    "import sklearn.linear_model\n",
    "import sklearn.tree\n",
    "import sklearn.ensemble\n",
    "import xgboost\n",
    "\n",
    "# hypertune\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# ML - accuracy\n",
    "import sklearn.metrics\n",
    "\n",
    "# Plot and visualize\n",
    "# import matplotlib.pyplot as plt\n",
    "# import shap\n",
    "\n",
    "# savemodel \n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup:\n",
    "- follow \"API credential step\" listed here: https://github.com/Kaggle/kaggle-api\n",
    "    - go to https://www.kaggle.com/ (login)\n",
    "    - go to my_profile (download kaggle.json)\n",
    "    - put it in ~/.kaggle/kaggle.json\n",
    "    - `cp ~/Downloads/kaggle.json ~/.kaggle/kaggle.json`\n",
    "    - `chmod 600 ~/.kaggle/kaggle.json`\n",
    "- Go to kaggle and join competition: \n",
    "    - https://www.kaggle.com/c/titanic\n",
    "- install kaggle\n",
    "- download data\n",
    "- profit!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "metadata = {\n",
    "    'basepath' : 'data/',\n",
    "    'dataset':'titanic',\n",
    "    'train' : 'train.csv',\n",
    "    'test' : 'test.csv'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading titanic.zip to data\n",
      "  0%|                                               | 0.00/34.1k [00:00<?, ?B/s]\n",
      "100%|██████████████████████████████████████| 34.1k/34.1k [00:00<00:00, 17.8MB/s]\n",
      "Archive:  data/titanic.zip\n",
      "  inflating: data/titanic/gender_submission.csv  \n",
      "  inflating: data/titanic/test.csv   \n",
      "  inflating: data/titanic/train.csv  \n"
     ]
    }
   ],
   "source": [
    "# make folder\n",
    "# download .zip\n",
    "# unzip\n",
    "# remove the .zip\n",
    "# (data is placed ../data/titanic)\n",
    "\n",
    "# !mkdir -p {metadata['basepath']}\n",
    "# !kaggle competitions download -c dataset {metadata['dataset']} -p {metadata['basepath']}\n",
    "# !unzip -o {metadata['basepath']}{metadata['dataset']}.zip -d {metadata['basepath']}{metadata['dataset']}/\n",
    "# !rm {metadata['basepath']}{metadata['dataset']}.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "train = pd.read_csv(\"{basepath}/{dataset}/{train}\".format(**metadata))\n",
    "test = pd.read_csv(\"{basepath}/{dataset}/{test}\".format(**metadata))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple imputation + cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(df):\n",
    "    dfc = df.copy()\n",
    "    \n",
    "    # Simple map\n",
    "    dfc['Sex'] = dfc['Sex'].map({\"female\":0,\"male\":1}).astype(int)\n",
    "    \n",
    "    # simple Impute\n",
    "    dfc['Age'] = dfc[\"Age\"].fillna(-1)\n",
    "    dfc['Fare'] = dfc[\"Fare\"].fillna(-1)\n",
    "\n",
    "    # Simple feature engineering (combining two variables)\n",
    "    dfc['FamilySize'] = dfc['SibSp'] + dfc['Parch'] + 1\n",
    "\n",
    "    # Simple feature engineering (converting to boolean)\n",
    "    dfc['Has_Cabin'] = dfc[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n",
    "    dfc = dfc.drop([\"Cabin\"],axis=1)\n",
    "    \n",
    "    # \"Stupid feature engineering - apply length \n",
    "    dfc['Name_length'] = dfc['Name'].apply(len)\n",
    "    dfc = dfc.drop([\"Name\"],axis=1)\n",
    "    dfc['Ticket_length'] = dfc['Ticket'].apply(len)\n",
    "    dfc = dfc.drop([\"Ticket\"],axis=1)\n",
    "    \n",
    "    # 1-hot encoding - different options are encoded as booleans\n",
    "    # ie. 1 categorical - become 3: 0-1 features.\n",
    "    dfc['Embarked_Q'] = dfc['Embarked'].apply(lambda x: 1 if x==\"Q\" else 0)\n",
    "    dfc['Embarked_S'] = dfc['Embarked'].apply(lambda x: 1 if x==\"S\" else 0)\n",
    "    dfc['Embarked_C'] = dfc['Embarked'].apply(lambda x: 1 if x==\"C\" else 0)\n",
    "    dfc = dfc.drop([\"Embarked\"],axis=1)\n",
    "    \n",
    "    \n",
    "    return dfc\n",
    "\n",
    "\n",
    "clean_train = clean(train)\n",
    "clean_test = clean(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(pd.DataFrame(clean_test.isna().mean() ,columns=[\"is na fraction\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"Survived\"\n",
    "\n",
    "y = clean_train[target]\n",
    "X = clean_train.drop([target],axis=1)\n",
    "\n",
    "# Split data in train and validation\n",
    "seed = 42\n",
    "test_size = 0.7\n",
    "\n",
    "X_train, X_val, y_train, y_val = sklearn.model_selection.train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    random_state = seed,\n",
    "    test_size = test_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost\n",
    "model_xgboost = xgboost.sklearn.XGBClassifier()\n",
    "model_xgboost.fit(X_train, y_train);\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done 393 tasks      | elapsed:    9.1s\n",
      "[Parallel(n_jobs=-1)]: Done 705 out of 720 | elapsed:   13.3s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed:   13.5s finished\n",
      "/Users/epedersen/.pyenv/versions/3.7.0/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=3, min_child_weight=1,\n",
       "       min_sample_split=3, missing=None, n_estimators=100, n_jobs=1,\n",
       "       nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=None, subsample=1, verbosity=1),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'n_estimators': [100, 200, 300], 'max_depth': [2, 3, 5, 8], 'min_sample_split': [2, 3, 5, 8], 'learning_rate': [0.05, 0.1, 0.5]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "xgb_param_grid = {\n",
    "        'n_estimators' : [100,200,300],\n",
    "        'max_depth': [2,3,5,8],\n",
    "        'min_sample_split': [2,3,5,8],\n",
    "        \"learning_rate\": [0.05,0.1,0.5]\n",
    "}\n",
    "\n",
    "\n",
    "model_xgboost_dummy = xgboost.sklearn.XGBClassifier(min_sample_split=3,learning_rate=0.1)\n",
    "grid_search_xgb = GridSearchCV(estimator = model_xgboost_dummy, param_grid = xgb_param_grid , \n",
    "                          cv = 5, n_jobs = -1, verbose = 2)\n",
    "\n",
    "grid_search_xgb.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.05,\n",
       " 'max_depth': 5,\n",
       " 'min_sample_split': 2,\n",
       " 'n_estimators': 100}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_grid = grid_search_xgb.best_params_\n",
    "display(best_grid)\n",
    "model_xgboost_best = xgboost.sklearn.XGBClassifier(**best_grid)\n",
    "model_xgboost_best.fit(X_train,y_train);\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_xgboost_best  | train:  0.959  | test:  0.812\n"
     ]
    }
   ],
   "source": [
    "\n",
    "models = {\n",
    "    \"model_xgboost_best\":model_xgboost_best\n",
    "}\n",
    "\n",
    "for name,model in zip(models.keys(),models.values()):\n",
    "    acc = sklearn.metrics.accuracy_score(\n",
    "     y_true = y_val,\n",
    "     y_pred = model.predict(X_val)\n",
    "    )\n",
    "    acc_train = sklearn.metrics.accuracy_score(\n",
    "     y_true = y_train,\n",
    "     y_pred = model.predict(X_train)\n",
    "    )\n",
    "    \n",
    "    print(name,\" | train: \",round(acc_train,3),\" | test: \",round(acc,3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "['data/model_xgboost_best.sav']"
      ],
      "text/plain": [
       "['data/model_xgboost_best.sav']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the model to disk\n",
    "\n",
    "filename =  metadata[\"basepath\"] + 'model_xgboost_best.sav'\n",
    "joblib.dump(model_xgboost_best, filename)\n",
    " \n",
    "# some time later...\n",
    " \n",
    "# load the model from disk\n",
    "#loaded_model = joblib.load(filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old predict for kaggle\n",
    "\n",
    "\n",
    "# passengerid\n",
    "# id = \"PassengerId\"\n",
    "# out = pd.DataFrame(data = test[id], columns = [id])\n",
    "\n",
    "# # target\n",
    "# out_target = model_xgboost_best.predict(clean_test)\n",
    "# out[target] = pd.DataFrame(out_target\n",
    "#                           ,columns = [target]\n",
    "#                           ,dtype=np.int32\n",
    "#                           )\n",
    "\n",
    "\n",
    "# # put them out\n",
    "# outfile = metadata[\"basepath\"] + \"output_xgboost.csv\"\n",
    "# out.to_csv(path_or_buf = outfile,\n",
    "#            index = False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
