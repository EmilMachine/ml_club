{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn import metrics\n",
    "import sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_file = \"../data/train.csv\"\n",
    "test_file = \"../data/test.csv\"\n",
    "\n",
    "\n",
    "train_data_raw = pd.read_csv(train_file)\n",
    "test_data_raw = pd.read_csv(test_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = clean_func(train_data_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "### CLEAN DATA FUNC\n",
    "\n",
    "def clean_func(train_data):\n",
    "    \n",
    "    ## DO IMPUTATION \n",
    "    # FARE\n",
    "    imp_fare = Imputer(missing_values=\"NaN\", strategy=\"mean\")\n",
    "    imp_fare.fit(train_data[[\"Fare\"]])\n",
    "    train_data[[\"Fare\"]]=imp_fare.transform(train_data[[\"Fare\"]]).ravel() \n",
    "\n",
    "    # Age\n",
    "    imp=Imputer(missing_values=\"NaN\", strategy=\"mean\")\n",
    "    imp.fit(train_data[[\"Age\"]])\n",
    "    train_data[[\"Age\"]]=imp.transform(train_data[[\"Age\"]]).ravel() \n",
    "    \n",
    "    # Filna\n",
    "    train_data[\"Cabin\"] = train_data[\"Cabin\"].fillna(\"\")\n",
    "\n",
    "    \n",
    "    # one hot encoding\n",
    "    sex_features = pd.get_dummies(train_data[\"Sex\"])\n",
    "    embarked_features = pd.get_dummies(train_data[\"Embarked\"])\n",
    "    \n",
    "    # rename embarked features\n",
    "    embarked_features = embarked_features.rename(columns={'C': 'embarked_cobh'\n",
    "                                                        , 'Q': 'embark_queenstown'\n",
    "                                                        , 'S': 'embark_southampton'})\n",
    "\n",
    "    # Concat new features\n",
    "    train_data_extras = pd.concat([train_data,sex_features,embarked_features],axis=1)\n",
    "\n",
    "    \n",
    "    \n",
    "    # HACK - REMOVE T WHICH IS NOT IN TEST LIKELY ERRROR \n",
    "    cabin_letters = pd.get_dummies(train_data['Cabin'].map(lambda x: \"empty\" if len(x)==0 or x[0]==\"T\" else x[0]))\n",
    "\n",
    "#    cabin_letters = pd.get_dummies(train_data['Cabin'].map(lambda x: \"empty\" if len(x)==0 else x[0]))\n",
    "    cabin_letters.columns = [\"Cabin_letter_\"+i for i in cabin_letters.columns]\n",
    "    train_data_extras = pd.concat([train_data_extras,cabin_letters],axis=1)\n",
    "    \n",
    "\n",
    "    train_data_extras[\"Cabin_number\"] = train_data['Cabin'].map(lambda x: -99 if len(x)==0 else x.split(\" \")[0][1:]) \n",
    "\n",
    "    return train_data_extras\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### NULL HANDLE\n",
    "imp=Imputer(missing_values=\"NaN\", strategy=\"mean\")\n",
    "imp.fit(train_data[[\"Age\"]])\n",
    "\n",
    "train_data[[\"Age\"]]=imp.transform(train_data[[\"Age\"]]).ravel() # what is ravel???\n",
    "\n",
    "train_data[\"Cabin\"] = train_data[\"Cabin\"].fillna(\"\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>...</th>\n",
       "      <th>embark_southampton</th>\n",
       "      <th>Cabin_letter_A</th>\n",
       "      <th>Cabin_letter_B</th>\n",
       "      <th>Cabin_letter_C</th>\n",
       "      <th>Cabin_letter_D</th>\n",
       "      <th>Cabin_letter_E</th>\n",
       "      <th>Cabin_letter_F</th>\n",
       "      <th>Cabin_letter_G</th>\n",
       "      <th>Cabin_letter_empty</th>\n",
       "      <th>Cabin_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare      ...      embark_southampton  \\\n",
       "0      0         A/5 21171   7.2500      ...                       1   \n",
       "1      0          PC 17599  71.2833      ...                       0   \n",
       "2      0  STON/O2. 3101282   7.9250      ...                       1   \n",
       "\n",
       "  Cabin_letter_A  Cabin_letter_B  Cabin_letter_C  Cabin_letter_D  \\\n",
       "0              0               0               0               0   \n",
       "1              0               0               1               0   \n",
       "2              0               0               0               0   \n",
       "\n",
       "   Cabin_letter_E  Cabin_letter_F  Cabin_letter_G  Cabin_letter_empty  \\\n",
       "0               0               0               0                   1   \n",
       "1               0               0               0                   0   \n",
       "2               0               0               0                   1   \n",
       "\n",
       "   Cabin_number  \n",
       "0           -99  \n",
       "1            85  \n",
       "2           -99  \n",
       "\n",
       "[3 rows x 26 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Sex', array(['male', 'female'], dtype=object))\n",
      "('Ticket', array(['A/5 21171', 'PC 17599', 'STON/O2. 3101282', '113803', '373450',\n",
      "       '330877', '17463', '349909', '347742', '237736', 'PP 9549',\n",
      "       '113783', 'A/5. 2151', '347082', '350406', '248706', '382652',\n",
      "       '244373', '345763', '2649'], dtype=object))\n",
      "('Cabin', array(['', 'C85', 'C123', 'E46', 'G6', 'C103', 'D56', 'A6', 'C23 C25 C27',\n",
      "       'B78', 'D33', 'B30', 'C52', 'B28', 'C83', 'F33', 'F G73', 'E31',\n",
      "       'A5', 'D10 D12'], dtype=object))\n",
      "('Embarked', array(['S', 'C', 'Q', nan], dtype=object))\n"
     ]
    }
   ],
   "source": [
    "# LOOK AT UNIQUE VALUES\n",
    "text_col = [\"Sex\",\"Ticket\",\"Cabin\",\"Embarked\"]\n",
    "\n",
    "for i in text_col:\n",
    "    print(i,train_data[i].unique()[0:20])\n",
    "\n",
    "## Sex, Embarked can be 1 hot encoded\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# one hot encoding\n",
    "sex_features = pd.get_dummies(train_data[\"Sex\"])\n",
    "embarked_features = pd.get_dummies(train_data[\"Embarked\"])\n",
    "train_data_extras = pd.concat([train_data,sex_features,embarked_features],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Advanced string processing\n",
    "# Name, Cabin, ticket\n",
    "\n",
    "## Remove all digits\n",
    "#tmp = train_data['Cabin'].map(lambda x: \"\".join([i for i in x if not i.isdigit()]))\n",
    "\n",
    "\n",
    "cabin_letters = pd.get_dummies(train_data['Cabin'].map(lambda x: \"empty\" if len(x)==0 else x[0]))\n",
    "cabin_letters.columns = [\"Cabin_letter_\"+i for i in cabin_letters.columns]\n",
    "train_data_extras = pd.concat([train_data_extras,cabin_letters],axis=1)\n",
    "\n",
    "\n",
    "train_data_extras[\"Cabin_number\"] = train_data['Cabin'].map(lambda x: -99 if len(x)==0 else x.split(\" \")[0][1:]) \n",
    "# train_data_extras.head()\n",
    "\n",
    "#[\"Cabin\"].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId           0\n",
       "Survived              0\n",
       "Pclass                0\n",
       "Name                  0\n",
       "Sex                   0\n",
       "Age                   0\n",
       "SibSp                 0\n",
       "Parch                 0\n",
       "Ticket                0\n",
       "Fare                  0\n",
       "Cabin                 0\n",
       "Embarked              2\n",
       "female                0\n",
       "male                  0\n",
       "embarked_cobn         0\n",
       "embark_queenstown     0\n",
       "embark_southampton    0\n",
       "Cabin_letter_A        0\n",
       "Cabin_letter_B        0\n",
       "Cabin_letter_C        0\n",
       "Cabin_letter_D        0\n",
       "Cabin_letter_E        0\n",
       "Cabin_letter_F        0\n",
       "Cabin_letter_G        0\n",
       "Cabin_letter_empty    0\n",
       "Cabin_number          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Null handling\n",
    "train_data.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PassengerId', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'female', 'male', 'embarked_cobn', 'embark_queenstown', 'embark_southampton', 'Cabin_letter_A', 'Cabin_letter_B', 'Cabin_letter_C', 'Cabin_letter_D', 'Cabin_letter_E', 'Cabin_letter_F', 'Cabin_letter_G', 'Cabin_letter_empty']\n",
      "Survived\n"
     ]
    }
   ],
   "source": [
    "target = \"Survived\"\n",
    "\n",
    "a = train_data.dtypes \n",
    "b = a[(a==\"int64\") | (a==\"float64\") | (a==\"uint8\")]\n",
    "numerics = [i for i in b.index if i not in target]\n",
    "\n",
    "\n",
    "\n",
    "print(numerics)\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "      <th>embarked_cobn</th>\n",
       "      <th>embark_queenstown</th>\n",
       "      <th>embark_southampton</th>\n",
       "      <th>Cabin_letter_A</th>\n",
       "      <th>Cabin_letter_B</th>\n",
       "      <th>Cabin_letter_C</th>\n",
       "      <th>Cabin_letter_D</th>\n",
       "      <th>Cabin_letter_E</th>\n",
       "      <th>Cabin_letter_F</th>\n",
       "      <th>Cabin_letter_G</th>\n",
       "      <th>Cabin_letter_empty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass   Age  SibSp  Parch     Fare  female  male  \\\n",
       "0            1       3  22.0      1      0   7.2500       0     1   \n",
       "1            2       1  38.0      1      0  71.2833       1     0   \n",
       "2            3       3  26.0      0      0   7.9250       1     0   \n",
       "\n",
       "   embarked_cobn  embark_queenstown  embark_southampton  Cabin_letter_A  \\\n",
       "0              0                  0                   1               0   \n",
       "1              1                  0                   0               0   \n",
       "2              0                  0                   1               0   \n",
       "\n",
       "   Cabin_letter_B  Cabin_letter_C  Cabin_letter_D  Cabin_letter_E  \\\n",
       "0               0               0               0               0   \n",
       "1               0               1               0               0   \n",
       "2               0               0               0               0   \n",
       "\n",
       "   Cabin_letter_F  Cabin_letter_G  Cabin_letter_empty  \n",
       "0               0               0                   1  \n",
       "1               0               0                   0  \n",
       "2               0               0                   1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[numerics].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(train_data[numerics]\n",
    "                              ,train_data[target].values\n",
    "                              ,test_size=0.3\n",
    "                              ,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "- logreg\n",
    "- random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression(penalty=\"l2\", dual=False, tol=0.0001, C=1.0\n",
    "                             , fit_intercept=True, intercept_scaling=1\n",
    "                             , class_weight=None, random_state=None\n",
    "                             , solver=\"liblinear\", max_iter=100\n",
    "                             , multi_class=\"ovr\", verbose=0\n",
    "                             , warm_start=False, n_jobs=1)\n",
    "\n",
    "log_reg.fit(X_train,Y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pred = log_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80223880597014929"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(Y_test,Y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### random forest naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=100, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf = RandomForestClassifier(\n",
    "n_estimators=100\n",
    ")\n",
    "\n",
    "model_rf.fit(train_data[numerics], train_data[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.8         0.78888889  0.76404494  0.83146067  0.91011236  0.83146067\n",
      "  0.82022472  0.7752809   0.86516854  0.86363636]\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation RF\n",
    "\n",
    "scores = cross_val_score(model_rf, train_data[numerics], train_data[target], cv=10)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81716417910447758"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_rf = model_rf.predict(X_test)\n",
    "metrics.accuracy_score(Y_test,pred_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_rf_gs = RandomForestClassifier()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': array([ 0.1,  0.2,  0.3,  0.4]), 'n_estimators': array([ 60,  80, 100]), 'criterion': ['gini', 'entropy'], 'min_samples_leaf': array([2, 3])}\n"
     ]
    }
   ],
   "source": [
    "# parmeter dict\n",
    "param_grid = dict(\n",
    "    n_estimators=np.arange(60,101,20)\n",
    "    , min_samples_leaf=np.arange(2,4,1)\n",
    "    , criterion = [\"gini\",\"entropy\"]\n",
    "    , max_features = np.arange(0.1,0.5,0.1)\n",
    ")\n",
    "print(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = GridSearchCV(model_rf_gs,param_grid=param_grid,scoring = \"accuracy\", cv = 5)\n",
    "grid.fit(train_data[numerics], train_data[target])\n",
    "\"\"\n",
    "# model_rf.fit(train_data[numerics], train_data[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(grid)\n",
    "# for i in ['params',\"mean_train_score\",\"mean_test_score\"]:\n",
    "#     print(i)\n",
    "#     print(grid.cv_results_[i])\n",
    "#grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 0.20000000000000001, 'n_estimators': 100, 'criterion': 'gini', 'min_samples_leaf': 3}\n",
      "0.828282828283\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)\n",
    "print(grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf_gs = RandomForestClassifier(**grid.best_params_)\n",
    "model_rf_gs.fit(train_data[numerics],train_data[target])\n",
    "\"\"\n",
    "#print(**grid.best_params_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.26215252]\n",
      "('PassengerId', 0.00029769529698762259)\n",
      "('Pclass', -0.61572589203732686)\n",
      "('Age', -0.029035069488013012)\n",
      "('SibSp', -0.25731235170696642)\n",
      "('Parch', -0.098679879797177933)\n",
      "('Fare', 0.0046425506773909841)\n",
      "('female', 1.9122432195029921)\n",
      "('male', -0.65009070419717296)\n",
      "('embarked_cobn', 0.70876233250311327)\n",
      "('embark_queenstown', 0.40782776801440723)\n",
      "('embark_southampton', 0.076421261776224214)\n",
      "('Cabin_letter_A', -0.11838698151573311)\n",
      "('Cabin_letter_B', 0.25698816555962745)\n",
      "('Cabin_letter_C', -0.56847577394182469)\n",
      "('Cabin_letter_D', 0.56817426992203868)\n",
      "('Cabin_letter_E', 1.2341569209168242)\n",
      "('Cabin_letter_F', 0.75928644755244623)\n",
      "('Cabin_letter_G', -0.54037042914426503)\n",
      "('Cabin_letter_empty', -0.32922010404327529)\n"
     ]
    }
   ],
   "source": [
    "# get parameters\n",
    "coef = list(log_reg.coef_.ravel())\n",
    "intercept = log_reg.intercept_\n",
    "\n",
    "# print them\n",
    "print intercept\n",
    "for id, i in enumerate(coef):\n",
    "    print(numerics[id],i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICT AND STORE OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### HACK TO COMPUTE TEST RESULT\n",
    "test_data = clean_func(test_data_raw)\n",
    "\n",
    "#test_data[[\"Age\"]]=imp.transform(test_data[[\"Age\"]]).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## DO IMPUTATION ON FARE\n",
    "# imp_fare = Imputer(missing_values=\"NaN\", strategy=\"mean\")\n",
    "# imp_fare.fit(train_data[[\"Fare\"]])\n",
    "\n",
    "# test_data[[\"Fare\"]]=imp_fare.transform(test_data[[\"Fare\"]]).ravel() # what is ravel???\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId           0\n",
       "Pclass                0\n",
       "Name                  0\n",
       "Sex                   0\n",
       "Age                   0\n",
       "SibSp                 0\n",
       "Parch                 0\n",
       "Ticket                0\n",
       "Fare                  0\n",
       "Cabin                 0\n",
       "Embarked              0\n",
       "female                0\n",
       "male                  0\n",
       "embarked_cobn         0\n",
       "embark_queenstown     0\n",
       "embark_southampton    0\n",
       "Cabin_letter_A        0\n",
       "Cabin_letter_B        0\n",
       "Cabin_letter_C        0\n",
       "Cabin_letter_D        0\n",
       "Cabin_letter_E        0\n",
       "Cabin_letter_F        0\n",
       "Cabin_letter_G        0\n",
       "Cabin_letter_empty    0\n",
       "Cabin_number          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test_data_y = log_reg.predict(test_data)\n",
    "test_data_y = log_reg.predict(test_data[numerics])\n",
    "\n",
    "\n",
    "#train_data[numerics].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output = pd.DataFrame(zip(list(test_data[\"PassengerId\"]),list(test_data_y)))\n",
    "output.columns = [\"PassengerId\",\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output.to_csv(index=False, path_or_buf= \"../data/output.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def output(data,file_name):\n",
    "    output = pd.DataFrame(zip(list(test_data[\"PassengerId\"]),list(data)))\n",
    "    output.columns = [\"PassengerId\",\"Survived\"]\n",
    "    output.to_csv(index=False, path_or_buf= \"../data/{file_name}.csv\".format(file_name=file_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_rf_data_y = model_rf.predict(test_data[numerics])\n",
    "\n",
    "output(model_rf_data_y,\"predict_rf_1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_rf_gs_data_y =model_rf_gs.predict(test_data[numerics])\n",
    "output(model_rf_gs_data_y,\"predict_rf_gs_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
